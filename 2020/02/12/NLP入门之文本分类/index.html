<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="NLP入门之文本分类"><meta name="keywords" content="NLP"><meta name="author" content="Rr-shan,undefined"><meta name="copyright" content="Rr-shan"><title>NLP入门之文本分类【Sanzzi】</title><link rel="stylesheet" href="../../../../css/fan.css"><link rel="stylesheet" href="../../../../css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="../../../../favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="../../../../js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#基本定义"><span class="toc-number">1.</span> <span class="toc-text">基本定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法1——k-近邻算法"><span class="toc-number">2.</span> <span class="toc-text">方法1——k 近邻算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法2——决策树"><span class="toc-number">3.</span> <span class="toc-text">方法2——决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法3——多层感知器"><span class="toc-number">4.</span> <span class="toc-text">方法3——多层感知器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法4——伯努力贝叶斯算法"><span class="toc-number">5.</span> <span class="toc-text">方法4——伯努力贝叶斯算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法5——高斯贝叶斯"><span class="toc-number">6.</span> <span class="toc-text">方法5——高斯贝叶斯</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法6——多项式朴素贝叶斯"><span class="toc-number">7.</span> <span class="toc-text">方法6——多项式朴素贝叶斯</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法7——逻辑回归算法"><span class="toc-number">8.</span> <span class="toc-text">方法7——逻辑回归算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法8——支持向量机算法"><span class="toc-number">9.</span> <span class="toc-text">方法8——支持向量机算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集成学习算法——方法1——随机森林算法"><span class="toc-number">10.</span> <span class="toc-text">集成学习算法——方法1——随机森林算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集成学习算法——方法2——自增强算法"><span class="toc-number">11.</span> <span class="toc-text">集成学习算法——方法2——自增强算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集成学习算法——方法3——lightgbm算法"><span class="toc-number">12.</span> <span class="toc-text">集成学习算法——方法3——lightgbm算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集成学习算法——方法4——xgboost算法"><span class="toc-number">13.</span> <span class="toc-text">集成学习算法——方法4——xgboost算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#深度学习算法——方法1——多分类前馈神经网络"><span class="toc-number">14.</span> <span class="toc-text">深度学习算法——方法1——多分类前馈神经网络</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Rr-shan</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/Rr-shan" target="_blank">GitHub<i class="icon-dot bg-color5"></i></a><a class="links-button button-hover" href="mailto:1224559633@qq.com" target="_blank">E-Mail<i class="icon-dot bg-color1"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="../../../../archives"><span class="pull-top">日志</span><span class="pull-bottom">38</span></a><a class="author-info-articles-tags article-meta" href="../../../../tags"><span class="pull-top">标签</span><span class="pull-bottom">11</span></a><a class="author-info-articles-categories article-meta" href="../../../../categories"><span class="pull-top">分类</span><span class="pull-bottom">12</span></a></div><div class="friend-link"><a class="friend-link-text" href="https://chao-yin-github.github.io/" target="_blank">yccccc~~~~~~~~</a><a class="friend-link-text" href="https://sanzzi.cn" target="_blank">Mywebsite</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">Sanzzi</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">NLP入门之文本分类</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2020-02-12 | 更新于 2020-04-03</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../categories/NLP/">NLP</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="../../../../tags/NLP/">NLP</a></div></div></div><div class="main-content"><h2 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xlrd <span class="comment"># 也可以使用pandas处理excel，非常好用</span></span><br><span class="line">workbook = xlrd.open_workbook(<span class="string">r'F:\C_1\train\train.xlsx'</span>)</span><br><span class="line">sheet = workbook.sheet_by_index(<span class="number">0</span>) <span class="comment"># sheet索引从0开始</span></span><br><span class="line">cols_1 = sheet.col_values(<span class="number">4</span>) <span class="comment"># 获取第3列内容</span></span><br><span class="line">cols_2 = sheet.col_values(<span class="number">5</span>)</span><br><span class="line">X_train = cols_1</span><br><span class="line">y_train = cols_2</span><br><span class="line"></span><br><span class="line">workbook1 = xlrd.open_workbook(<span class="string">r'F:\C_1\test\test.xlsx'</span>)</span><br><span class="line">sheet = workbook1.sheet_by_index(<span class="number">0</span>)</span><br><span class="line">cols_3 = sheet.col_values(<span class="number">4</span>)</span><br><span class="line">cols_4 = sheet.col_values(<span class="number">5</span>)</span><br><span class="line">X_test = cols_3</span><br><span class="line">y_test = cols_4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去掉空格</span></span><br><span class="line">X_train_word = [jieba.cut(words) <span class="keyword">for</span> words <span class="keyword">in</span> X_train]</span><br><span class="line">X_train_cut = [<span class="string">' '</span>.join(word) <span class="keyword">for</span> word <span class="keyword">in</span> X_train_word]</span><br><span class="line">X_test_word = [jieba.cut(words) <span class="keyword">for</span> words <span class="keyword">in</span> X_test]</span><br><span class="line">X_test_cut  = [<span class="string">' '</span>.join(word) <span class="keyword">for</span> word <span class="keyword">in</span> X_test_word]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 停止词使用</span></span><br><span class="line">stoplist = [word.strip() <span class="keyword">for</span> word <span class="keyword">in</span> open(<span class="string">'F:\MLstudy\stop\stopword.txt'</span>, \</span><br><span class="line">                                           encoding=<span class="string">'utf-8'</span>).readlines()]</span><br><span class="line"><span class="comment"># from sklearn.preprocessing import LabelEncoder</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y_train_le = le.fit_transform(y_train)</span><br><span class="line">y_test_le  = le.fit_transform(y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#文本数据转换成数据值数据矩阵</span></span><br><span class="line"><span class="comment"># from sklearn.feature_extraction.text import CountVectorizer</span></span><br><span class="line">count = CountVectorizer(stop_words=stoplist)</span><br><span class="line"></span><br><span class="line">count.fit(list(X_train_cut) + list(X_test_cut))</span><br><span class="line">X_train_count = count.transform(X_train_cut)</span><br><span class="line">X_test_count  = count.transform(X_test_cut)</span><br><span class="line"></span><br><span class="line">X_train_count = X_train_count.toarray()</span><br><span class="line">X_test_count  = X_test_count.toarray()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于存储所有算法的名字，准确率和所消耗的时间</span></span><br><span class="line">estimator_list, score_list, time_list = [], [], []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_text_classification</span><span class="params">(estimator, X, y, X_test, y_test)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    estimator: 分类器，必选参数</span></span><br><span class="line"><span class="string">            X: 特征训练数据，必选参数</span></span><br><span class="line"><span class="string">            y: 标签训练数据，必选参数</span></span><br><span class="line"><span class="string">       X_test: 特征测试数据，必选参数</span></span><br><span class="line"><span class="string">        y_tes: 标签测试数据，必选参数</span></span><br><span class="line"><span class="string">       return: 返回值</span></span><br><span class="line"><span class="string">           y_pred_model: 预测值</span></span><br><span class="line"><span class="string">             classifier: 分类器名字</span></span><br><span class="line"><span class="string">                  score: 准确率</span></span><br><span class="line"><span class="string">                      t: 消耗的时间</span></span><br><span class="line"><span class="string">                  matrix: 混淆矩阵</span></span><br><span class="line"><span class="string">                  report: 分类评价函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;算法正在启动，请稍候...'</span>)</span><br><span class="line">    model = estimator</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;算法正在进行训练，请稍候...'</span>)</span><br><span class="line">    model.fit(X, y)</span><br><span class="line">    print(model)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;算法正在进行预测，请稍候...'</span>)</span><br><span class="line">    y_pred_model = model.predict(X_test)</span><br><span class="line">    print(y_pred_model)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;算法正在进行性能评估，请稍候...'</span>)</span><br><span class="line">    score = metrics.accuracy_score(y_test, y_pred_model)</span><br><span class="line">    matrix = metrics.confusion_matrix(y_test, y_pred_model)</span><br><span class="line">    report = metrics.classification_report(y_test, y_pred_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     f1 = metrics.f1_score(y_test, y_pred_model,average='weighted') #这是加权的</span></span><br><span class="line">    f1 = metrics.f1_score(y_test, y_pred_model, average=<span class="string">'macro'</span>)</span><br><span class="line">    print(<span class="string">'&gt;&gt;&gt;准确率\n'</span>, score)</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;混淆矩阵\n'</span>, matrix)</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;召回率\n'</span>, report)</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;F1 score\n'</span>, f1)</span><br><span class="line">    print(<span class="string">'&gt;&gt;&gt;算法程序已经结束...'</span>)</span><br><span class="line"></span><br><span class="line">    end = time.time()</span><br><span class="line">    t = end - start</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;算法消耗时间为：'</span>, t, <span class="string">'秒\n'</span>)</span><br><span class="line">    classifier = str(model).split(<span class="string">'('</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred_model, classifier, score, round(t, <span class="number">2</span>), matrix, report</span><br></pre></td></tr></table></figure>

<h2 id="方法1——k-近邻算法"><a href="#方法1——k-近邻算法" class="headerlink" title="方法1——k 近邻算法"></a>方法1——k 近邻算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knc = KNeighborsClassifier()</span><br><span class="line">result = get_text_classification(knc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法2——决策树"><a href="#方法2——决策树" class="headerlink" title="方法2——决策树"></a>方法2——决策树</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">dtc = DecisionTreeClassifier()</span><br><span class="line">result = get_text_classification(dtc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法3——多层感知器"><a href="#方法3——多层感知器" class="headerlink" title="方法3——多层感知器"></a>方法3——多层感知器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"></span><br><span class="line">mlpc = MLPClassifier()</span><br><span class="line">result = get_text_classification(mlpc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法4——伯努力贝叶斯算法"><a href="#方法4——伯努力贝叶斯算法" class="headerlink" title="方法4——伯努力贝叶斯算法"></a>方法4——伯努力贝叶斯算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> BernoulliNB</span><br><span class="line"></span><br><span class="line">bnb = BernoulliNB()</span><br><span class="line">result = get_text_classification(bnb, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法5——高斯贝叶斯"><a href="#方法5——高斯贝叶斯" class="headerlink" title="方法5——高斯贝叶斯"></a>方法5——高斯贝叶斯</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"></span><br><span class="line">gnb = GaussianNB()</span><br><span class="line">result = get_text_classification(gnb, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法6——多项式朴素贝叶斯"><a href="#方法6——多项式朴素贝叶斯" class="headerlink" title="方法6——多项式朴素贝叶斯"></a>方法6——多项式朴素贝叶斯</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"></span><br><span class="line">mnb = MultinomialNB()</span><br><span class="line">result = get_text_classification(mnb, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法7——逻辑回归算法"><a href="#方法7——逻辑回归算法" class="headerlink" title="方法7——逻辑回归算法"></a>方法7——逻辑回归算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lgr = LogisticRegression()</span><br><span class="line">result = get_text_classification(lgr, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="方法8——支持向量机算法"><a href="#方法8——支持向量机算法" class="headerlink" title="方法8——支持向量机算法"></a>方法8——支持向量机算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line">svc = svm.SVC()</span><br><span class="line">result = get_text_classification(svc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="集成学习算法——方法1——随机森林算法"><a href="#集成学习算法——方法1——随机森林算法" class="headerlink" title="集成学习算法——方法1——随机森林算法"></a>集成学习算法——方法1——随机森林算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line">result = get_text_classification(rfc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="集成学习算法——方法2——自增强算法"><a href="#集成学习算法——方法2——自增强算法" class="headerlink" title="集成学习算法——方法2——自增强算法"></a>集成学习算法——方法2——自增强算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"></span><br><span class="line">abc = AdaBoostClassifier()</span><br><span class="line">result = get_text_classification(abc, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="集成学习算法——方法3——lightgbm算法"><a href="#集成学习算法——方法3——lightgbm算法" class="headerlink" title="集成学习算法——方法3——lightgbm算法"></a>集成学习算法——方法3——lightgbm算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm</span><br><span class="line"></span><br><span class="line">gbm = lightgbm.LGBMClassifier()</span><br><span class="line">result = get_text_classification(gbm, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="集成学习算法——方法4——xgboost算法"><a href="#集成学习算法——方法4——xgboost算法" class="headerlink" title="集成学习算法——方法4——xgboost算法"></a>集成学习算法——方法4——xgboost算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"></span><br><span class="line">xgb = xgboost.XGBClassifier()</span><br><span class="line">result = get_text_classification(xgb, X_train_count, y_train_le, X_test_count, y_test_le)</span><br><span class="line">estimator_list.append(result[<span class="number">1</span>]), score_list.append(result[<span class="number">2</span>]), time_list.append(result[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="深度学习算法——方法1——多分类前馈神经网络"><a href="#深度学习算法——方法1——多分类前馈神经网络" class="headerlink" title="深度学习算法——方法1——多分类前馈神经网络"></a>深度学习算法——方法1——多分类前馈神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="comment"># --------------------------------</span></span><br><span class="line"><span class="comment"># np.random.seed(0)     # 设置随机数种子</span></span><br><span class="line">feature_num = X_train_count.shape[<span class="number">1</span>]     <span class="comment"># 设置所希望的特征数量</span></span><br><span class="line"><span class="comment"># print(feature_num)</span></span><br><span class="line"><span class="comment"># ---------------------------------</span></span><br><span class="line"><span class="comment"># 独热编码目标向量来创建目标矩阵</span></span><br><span class="line">y_train_cate = to_categorical(y_train_le)</span><br><span class="line">y_test_cate = to_categorical(y_test_le)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 1 创建神经网络</span></span><br><span class="line">network = models.Sequential() </span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 2 添加神经连接层</span></span><br><span class="line"><span class="comment"># 第一层必须有并且一定是 [输入层], 必选</span></span><br><span class="line">network.add(layers.Dense(     <span class="comment"># 添加带有 relu 激活函数的全连接层</span></span><br><span class="line">                         units=<span class="number">128</span>, </span><br><span class="line">                         activation=<span class="string">'relu'</span>, </span><br><span class="line">                         input_shape=(feature_num, )</span><br><span class="line">                         ))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 介于第一层和最后一层之间的称为 [隐藏层]，可选</span></span><br><span class="line">network.add(layers.Dense(     <span class="comment"># 添加带有 relu 激活函数的全连接层</span></span><br><span class="line">                         units=<span class="number">128</span>, </span><br><span class="line">                         activation=<span class="string">'relu'</span></span><br><span class="line">                         ))</span><br><span class="line">network.add(layers.Dropout(<span class="number">0.8</span>))</span><br><span class="line"><span class="comment"># network.add(layers.Dropout(0.4))</span></span><br><span class="line"><span class="comment"># 最后一层必须有并且一定是 [输出层], 必选                         </span></span><br><span class="line">network.add(layers.Dense(     <span class="comment"># 添加带有 softmax 激活函数的全连接层</span></span><br><span class="line">                         units=<span class="number">8</span>,</span><br><span class="line">                         activation=<span class="string">'sigmoid'</span></span><br><span class="line">                         ))</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 3 编译神经网络</span></span><br><span class="line">network.compile(loss=<span class="string">'categorical_crossentropy'</span>,  <span class="comment"># 分类交叉熵损失函数    </span></span><br><span class="line">                optimizer=<span class="string">'rmsprop'</span>,  </span><br><span class="line">                metrics=[<span class="string">'accuracy'</span>]              <span class="comment"># 准确率度量</span></span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 4 开始训练神经网络</span></span><br><span class="line">history = network.fit(X_train_count,     <span class="comment"># 训练集特征</span></span><br><span class="line">            y_train_cate,        <span class="comment"># 训练集标签</span></span><br><span class="line">            epochs=<span class="number">20</span>,          <span class="comment"># 迭代次数</span></span><br><span class="line">            batch_size=<span class="number">300</span>,    <span class="comment"># 每个批量的观测数  可做优化</span></span><br><span class="line">            validation_data=(X_test_count, y_test_cate)  <span class="comment"># 验证测试集数据</span></span><br><span class="line">            )</span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------</span></span><br><span class="line"><span class="comment"># 6 性能评估</span></span><br><span class="line">print(<span class="string">'&gt;&gt;&gt;多分类前馈神经网络性能评估如下...\n'</span>)</span><br><span class="line">score = network.evaluate(X_test_count,</span><br><span class="line">                        y_test_cate,</span><br><span class="line">                        batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\n&gt;&gt;&gt;评分\n'</span>, score)</span><br><span class="line">print()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">estimator_list.append(<span class="string">'前馈网络'</span>)</span><br><span class="line">score_list.append(score[<span class="number">1</span>])</span><br><span class="line">time_list.append(round(end-start, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Rr-shan</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://rr-shan.github.io/2020/02/12/NLP入门之文本分类/">https://rr-shan.github.io/2020/02/12/NLP入门之文本分类/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://rr-shan.github.io">Sanzzi</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../13/Python词云/"><i class="fas fa-angle-left">&nbsp;</i><span>Python词云</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="../../10/惩罚线性回归模型/"><span>惩罚线性回归模型</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Rr-shan</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="../../../../js/copy.js"></script><!--script(src=url)--><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/haruto.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>