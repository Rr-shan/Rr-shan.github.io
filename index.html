<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content><meta name="keywords" content><meta name="author" content="Rr-shan,undefined"><meta name="copyright" content="Rr-shan"><title>【Sanzzi】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="/favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="author-info"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Rr-shan</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/Rr-shan" target="_blank">GitHub<i class="icon-dot bg-color8"></i></a><a class="links-button button-hover" href="mailto:1224559633@qq.com" target="_blank">E-Mail<i class="icon-dot bg-color6"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="archives"><span class="pull-top">日志</span><span class="pull-bottom">44</span></a><a class="author-info-articles-tags article-meta" href="tags"><span class="pull-top">标签</span><span class="pull-bottom">12</span></a><a class="author-info-articles-categories article-meta" href="categories"><span class="pull-top">分类</span><span class="pull-bottom">12</span></a></div><div class="friend-link"><a class="friend-link-text" href="https://chao-yin-github.github.io/" target="_blank">yccccc~~~~~~~~</a><a class="friend-link-text" href="https://sanzzi.cn" target="_blank">Mywebsite</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="title-name" href="/">Sanzzi</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><div id="recent-posts"><!-- each post in page.posts.sort('date', -1).limit(10).toArray()--><!-- config中配置按照什么排序--><div class="recent-post-item"><a class="post-title" href="2020/04/20/srf之论文阅读Graph_embedding_review/">srf之论文阅读Graph_embedding_review</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-20</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="categories/DeepLearning/">DeepLearning</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="tags/srf/">srf</a></div></div><div class="post-content"><div class="main-content content"><p>@[TOC](Graph embedding on biomedical networks: methods, applications and evaluations)</p>
<h1 id="1-研究背景"><a href="#1-研究背景" class="headerlink" title="1.研究背景"></a>1.研究背景</h1><p>研究者提出了大量的图嵌入（又称网络嵌入或图表示学习）的方法去<strong>自动学习图中每个节点的低维特征表示</strong>。<br>直观上看，图嵌入方法是通过学习低维表示来<strong>保留图的结构信息</strong>，从而完成像链接预测，社区检测，节点分类和聚类等相关任务。</p>
<h2 id="1-1作用"><a href="#1-1作用" class="headerlink" title="1.1作用"></a>1.1作用</h2><h3 id="1-1-1链接预测任务"><a href="#1-1-1链接预测任务" class="headerlink" title="1.1.1链接预测任务:"></a>1.1.1链接预测任务:</h3><ol>
<li><strong>药物-疾病</strong>关联（drug-disease association, <strong>DDA</strong>）预测</li>
<li><strong>药物-药物</strong>相互作用（drug- drug interaction, <strong>DDI</strong>）预测</li>
<li><strong>蛋白质-蛋白质</strong>相互作用（protein - protein interaction, <strong>PPI</strong>）预测; </li>
</ol>
<h3 id="1-1-2节点分类任务"><a href="#1-1-2节点分类任务" class="headerlink" title="1.1.2节点分类任务:"></a>1.1.2节点分类任务:</h3><ol start="4">
<li>医学术语语义类型分类</li>
<li>蛋白质功能预测进行了系统的比较</li>
</ol>
<h3 id="1-1-3本文的亮点"><a href="#1-1-3本文的亮点" class="headerlink" title="1.1.3本文的亮点"></a>1.1.3本文的亮点</h3><p>对于以上5个任务，研究者编制了<strong>7个基准数据集</strong>（这些数据集来源于常用的生物医学数据库或已有的研究），并使用它们来系统地评估<strong>11个不同类别中有代表性的图形嵌入方法</strong>（其中5个基于矩阵分解（MF），3个基于随机游走，3个基于神经网络）</p>
<h1 id="2-图嵌入方法概述"><a href="#2-图嵌入方法概述" class="headerlink" title="2.图嵌入方法概述"></a>2.图嵌入方法概述</h1><p><img src="https://img-blog.csdnimg.cn/20200419103312753.png" alt="在这里插入图片描述"></p>
<h2 id="2-1基于MF的方法："><a href="#2-1基于MF的方法：" class="headerlink" title="2.1基于MF的方法："></a>2.1基于MF的方法：</h2><p>MF已经被广泛用于数据分析，它的目的是<strong>将一个数据矩阵分解为低维矩阵，同时保留原数据矩阵中隐藏的流形结构和拓扑特性。</strong><br>传统MF有许多变体，例如<strong>奇异值分解（SVD）</strong>和<strong>图分解（GF）</strong>。<br>近年来，研究人员专注于设计各种<strong>高阶数据邻近矩阵以保留图结构</strong>，并提出了各种基于MF的图嵌入学习方法。文中介绍了<strong>GraRep， HOPE</strong>方法的特点和区别。</p>
<h2 id="2-2基于随机游走的方法："><a href="#2-2基于随机游走的方法：" class="headerlink" title="2.2基于随机游走的方法："></a>2.2基于随机游走的方法：</h2><p>受word2vec模型的启发，针对图数据结构开发了<strong>基于随机游走的方法</strong>，即通过随机游走生成<strong>节点序列</strong>来学习节点表示形式，然后再对生成的节点序列进行嵌入。<br><strong>DeepWalk</strong>是这种基于随机游走进行图嵌入最早的方法之一。<br>与DeepWalk相比，<strong>node2vec</strong>采用了<strong>灵活的偏差随机游走策略</strong>， <strong>struc2vec</strong>可以更好地识别<strong>结构标识。</strong></p>
<h2 id="2-3基于神经网络的方法："><a href="#2-3基于神经网络的方法：" class="headerlink" title="2.3基于神经网络的方法："></a>2.3基于神经网络的方法：</h2><p>近年来神经网络模型在许多领域成功应用，在图形嵌入领域也引入了多种神经网络，例如多层感知器（MLP），自编码器，生成对抗网络（GAN）和图卷积网络（GCN）。文中具体介绍了<strong>LINE，SDNE，GAE</strong>这些方法。<br><img src="https://img-blog.csdnimg.cn/20200419103729723.png" alt="在这里插入图片描述"></p>
<h1 id="3-任务基本介绍"><a href="#3-任务基本介绍" class="headerlink" title="3.任务基本介绍"></a>3.任务基本介绍</h1><h2 id="3-1链接预测"><a href="#3-1链接预测" class="headerlink" title="3.1链接预测"></a>3.1链接预测</h2><p>链接预测任务可以表述为：<strong>给定一组生物医学实体及其已知的相互作用，去预测实体之间潜在的相互作用。</strong><br>生物医学领域的传统方法主要是通过特征工程来开发生物学特征。<br>监督学习方法（例如支持向量机器（SVM），随机森林）或半监督的图推理模型（如标签传播）也被用于预测潜在的相互作用。<br>这些方法背后的假设是，<strong>共享相似生物学特征或图特征的实体可能具有相似的关联</strong>。<br>然而，通常面临两个问题：</p>
<ol>
<li>生物学特征<strong>获取困难</strong>，成本高且不一定能用。</li>
<li>生物学特征以及手工制作的图形特征（例如节点度），不足以精确的表示或描述生物医学实体。</li>
</ol>
<p><em>自动学习节点表示的图嵌入方法有望解决这两个问题。</em><br>比如针对三个重要的链接预测任务：</p>
<ol>
<li>DDA的预测：基于MF的技术用于DDA的预测，其本质上，是将<strong>DDA矩阵分解来学习药物和疾病在潜在空间中的低维表示</strong>。在因子分解过程中，可以加入<strong>正则化项或约束</strong>来进一步提高潜在表示的质量。</li>
<li>对于DDIs的预测，提出了多种正则化MF，利用<strong>Laplacian正则化</strong>来学习更好的药物表征。此外，还引入了<strong>图神经网络</strong>用于DDI的预测。</li>
<li>PPIs通常使用<strong>Laplacian和SVD</strong>技术进行预测。现在有研究提出了一种<strong>基于自动编码器的模型</strong>来学习蛋白质的嵌入，其设计与SDNE相似。</li>
</ol>
<h2 id="3-2节点分类"><a href="#3-2节点分类" class="headerlink" title="3.2节点分类"></a>3.2节点分类</h2><ul>
<li>节点分类目的是<strong>预测局部标记图中未标记节点的类别。</strong></li>
</ul>
<h3 id="3-2-1蛋白质功能预测"><a href="#3-2-1蛋白质功能预测" class="headerlink" title="3.2.1蛋白质功能预测"></a>3.2.1蛋白质功能预测</h3><p>大规模的实验对蛋白质的功能注释<strong>非常昂贵</strong>，近年来提出了基于图的计算方法广泛地融合了图嵌入的思想。<br>例如：</p>
<ul>
<li>一种基于<strong>拉普拉斯核的正则化方法</strong>来学习蛋白质的低维嵌入；</li>
<li><strong>Mashup</strong>方法在PPI网络上执行带有<strong>重启的随机游走（RWR）</strong>，通过低秩矩阵近似方法（可通过SVD优化）学习每个蛋白质的嵌入，再将这些特征向量输入分类器以获得关于基因或蛋白质的功能性信息；</li>
<li><strong>DeepGO</strong>通过卷积神经网络和图形嵌入方法学习基于蛋白序列的蛋白联合表达和PPI网络（类似于DeepWalk）；</li>
<li><strong>node2vec</strong>嵌入方法在PPI网络上进行蛋白质的节点分类也是非常有效的。</li>
<li><strong>OhmNet</strong>可以基于node2vec优化分层依赖目标，以学习多层组织网络中的特征表示，用于功能预测；</li>
<li><strong>deepNF</strong>通过一个深度自编码器来学习蛋白质的嵌入（类似于SDNE）。</li>
</ul>
<h3 id="3-2-2医学术语语义类型分类"><a href="#3-2-2医学术语语义类型分类" class="headerlink" title="3.2.2医学术语语义类型分类"></a>3.2.2医学术语语义类型分类</h3><p>在过去的几年里，临床文献的增加一直在鼓励研究者开发出能够从这些数据中挖掘有用信息的模型，进而来<strong>改善</strong>患者的个人护理以及帮助临床决策。<br>由于原始临床文本访问的限制，医学术语语义类型的缺失等种种原因，针对医学术语语义类型的分类虽然很有意义，但已有的研究很少。</p>
<p>本文作者的研究团队制定了一个节点分类任务：</p>
<ul>
<li>给定医学术语共现图，其中的术语和共现统计是从<strong>公开的临床文本中提取出来的</strong>，对医学术语的语义类型进行分类。</li>
<li>在这项工作中，作者假设<strong>临床文本已转换为医学术语-术语共现图</strong>，其中每个<strong>节点</strong>是一个提取的<strong>医学术语</strong>，每条<strong>边</strong>是一个上下文窗口中两个术语的<strong>共现的次数</strong>。</li>
<li>将图嵌入方法应用于共现图来学习医学术语的表示，然后利用学习到的嵌入表示训练<strong>多标签分类器</strong>对医学术语进行语义分类。<br><img src="https://img-blog.csdnimg.cn/20200419110137154.png" alt="在这里插入图片描述"><h1 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4.数据集"></a>4.数据集</h1>作者在本节中介绍了7个编制数据集的详细信息，包括<strong>两个DDA图</strong>，<strong>一个DDI图</strong>和<strong>一个PPI图</strong>用于链接预测；一个<strong>医学术语-术语共现图</strong>和<strong>两个PPI图</strong>用于节点分类。<br><img src="https://img-blog.csdnimg.cn/20200419110921961.png" alt="在这里插入图片描述"></li>
</ul>
<h1 id="5-结果"><a href="#5-结果" class="headerlink" title="5.结果"></a>5.结果</h1><h2 id="5-1链接预测任务"><a href="#5-1链接预测任务" class="headerlink" title="5.1链接预测任务"></a>5.1链接预测任务</h2><p><img src="https://img-blog.csdnimg.cn/20200419111550580.png" alt="在这里插入图片描述"></p>
<h2 id="5-2分类任务"><a href="#5-2分类任务" class="headerlink" title="5.2分类任务"></a>5.2分类任务</h2><p><img src="https://img-blog.csdnimg.cn/20200419111710189.png" alt="在这里插入图片描述"></p>
<h1 id="6-超参数的通用原则"><a href="#6-超参数的通用原则" class="headerlink" title="6.超参数的通用原则"></a>6.超参数的通用原则</h1><p>作者总结了一些设置超参数的通用原则，帮助研究人员更好地设置超参数。<br><img src="https://img-blog.csdnimg.cn/20200419112057922.png" alt="在这里插入图片描述"></p>
<h1 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h1><ul>
<li><strong>概述了各种图嵌入技术</strong></li>
<li>在<strong>链接预测和节点分类</strong>两个重要的生物医学任务上的性能进行了评估。<br>作者从公共数据库或以前的研究中编制了<strong>7个数据集</strong>，并利用这些数据库对<strong>11种有代表性的图嵌入方法</strong>进行了基准测试。<br>通过大量的实验，发现了目前的图嵌入方法在各种生物医学预测任务中表现良好，并且与现有的方法相比，具有很强的竞争力或更好的性能。<br>此外，作者调整了图嵌入方法的一些<strong>重要超参数</strong>，并为从业者提供了设置超参数的一般指导。<br>作者也讨论了最近的网络传播（扩散）方法与图嵌入方法之间的联系，以及潜在的方向（如图嵌入的转移学习），以启发未来的工作。</li>
</ul>
</div></div><a class="button-hover more" href="2020/04/20/srf之论文阅读Graph_embedding_review/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/04/14/srf之论文阅读A3NCF/">srf之论文阅读A3NCF</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-14</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="categories/DeepLearning/">DeepLearning</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="tags/srf/">srf</a></div></div><div class="post-content"><div class="main-content content"><h1 id="A3NCF-An-Adaptive-Aspect-Attention-Model-for-Rating-Prediction"><a href="#A3NCF-An-Adaptive-Aspect-Attention-Model-for-Rating-Prediction" class="headerlink" title="A3NCF: An Adaptive Aspect Attention Model for Rating Prediction"></a>A3NCF: An Adaptive Aspect Attention Model for Rating Prediction</h1><hr>
<h2 id="1-为什么要讲这个-amp-传统方法有什么问题-（对比）"><a href="#1-为什么要讲这个-amp-传统方法有什么问题-（对比）" class="headerlink" title="1. 为什么要讲这个?&amp; 传统方法有什么问题?（对比）"></a>1. 为什么要讲这个?&amp; 传统方法有什么问题?（对比）</h2><ul>
<li>提出了<strong>矩阵分解</strong>的一些不足之处，用户对物品的一个rate只是用户对其的一个<strong>总体评价</strong>，<em>缺少可解释性</em>。<blockquote>
<p>例如：一个用户对一部手机有较高的评分可能只是因为它的摄像头好或者是电池的续航能力强，但是这并不代表对这部手机的整体有了一个很高的评价。所以说MF并不能实现<strong>细粒度的建模。</strong></p>
</blockquote>
</li>
<li>基于这个限制，研究者们将目光转向了<strong>文本评论</strong>，评论中包含了很多丰富的信息，由于深度学习有着很强的提取特征能力，研究者们用它来学习评论中<strong>用户的喜好</strong>和<strong>物品的特征</strong>。虽然这些方法比起MF有着更好的性能，但是忽略了一点：<strong>一个用户</strong>在同一方面，对不同的物品的喜好程度或者要求是不一样的。（更有针对性！）</li>
<li>目前的方法都没有考虑到一个用户在同一物品的关注方面可能是多样的情况。<blockquote>
<p>例如，对于<strong>高品质手机</strong>，用户可能更关注于<strong>高像素、低耗量</strong>。而对于<strong>廉价手机</strong>，用户可能更关注于<strong>通讯的质量</strong>。</p>
</blockquote>
</li>
</ul>
<h2 id="2-提出了什么方法-有什么创新点"><a href="#2-提出了什么方法-有什么创新点" class="headerlink" title="2. 提出了什么方法 ? 有什么创新点"></a>2. 提出了什么方法 ? 有什么创新点</h2><p>A3NCF模型，一个新的主题模型以同时提取<strong>用户的偏好</strong>和物品的特征，可以准确地捕获<strong>用户对不同物品各个方面的关注</strong>。<br>它不同于之前的topic-based method直接利用LDA对评论进行提取项目特征。</p>
<ul>
<li><strong>aspect-level</strong>分成两个部分，一个是<strong>基于主题模型</strong>，一个是<strong>基于Attention network中隐层k</strong>。</li>
</ul>
<ol>
<li><strong>主题模型中</strong>将评论拆分为独立的句子，认为每个句子表示一个aspect信息，采用贝努利概率分布构建基于aspect的用户和物品的隐式主题向量。</li>
<li><strong>在神经网络端</strong>，作者参考了AFM模型，认为隐层K具有代表不同aspect信息的能力，采用attention的方法增强区分不同aspect的重要程度的能力。</li>
</ol>
<h2 id="3-原理"><a href="#3-原理" class="headerlink" title="3. 原理"></a>3. 原理</h2><p><img src="https://img-blog.csdnimg.cn/2019102913394761.png?" alt="在这里插入图片描述"><br>该模型主要分为四个模块</p>
<ul>
<li><strong>Input</strong></li>
<li><strong>Feature Fusion</strong></li>
<li><strong>Attentive Interaction</strong></li>
<li><strong>Rating Prediction</strong><h3 id="1-Input模块"><a href="#1-Input模块" class="headerlink" title="1. Input模块"></a>1. Input模块</h3>是由基于主题模型的用户和物品评论表示，以及基于<strong>one-hot编码</strong>的用户和物品的隐层表示作为输入。<br>在<strong>主题模型</strong>当中，作者对原来的<strong>LDA模型</strong>中引入了<strong>贝努利概率分布</strong>，<em>增强模型在用户和物品对不同aspect-level的topic的学习能力。</em><br><img src="https://img-blog.csdnimg.cn/20190524135731807.png?" alt="在这里插入图片描述"><h4 id="对应算法："><a href="#对应算法：" class="headerlink" title="对应算法："></a>对应算法：</h4><img src="https://img-blog.csdnimg.cn/20190524141219360.png" alt="在这里插入图片描述"><br>符号解释：<br>在图中，阴影圆圈表示观察到的变量w，而无阴影圆圈表示潜在变量。<br>M：用户数量<br>N：物品数量<br>D：语料库 （其中包含用户对项目的评论，d u，i∈D）<br>为了确定句子s的主题Zs，我们的模型引入了指标变量y∈{0,1}基于伯努利分布，该分布由π u。（因为对于不同的项目，用户可能会在不同的方面进行评论，这也反映了用户对不同项目的方面的关注。因此，πu是用户相关的，表示用户u倾向于根据自己的偏好或根据项目i的特征进行评论。）</li>
</ul>
<p>具体来说，当y = 0时，句子是从用户的偏好； 否则，它是根据项目的特征。<br><em>代码体现</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; K; k++) &#123;</span><br><span class="line">	<span class="comment">// common part</span></span><br><span class="line">	<span class="keyword">double</span> common_part = (nkt[k][doc[m][n]] + beta) / (nktSum[k] + betaSum);</span><br><span class="line">	<span class="comment">// first part is when y = 0; // USER</span></span><br><span class="line">	p[k] = (eta[<span class="number">0</span>] + Ny0[userIdx]) * common_part * ((nuk[userIdx][k] + alpha_u) / (nukSum[userIdx] + alphaSum));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// second part is when y = 1 // ITEM</span></span><br><span class="line">	p[k + K] = (eta[<span class="number">1</span>] + Ny1[userIdx]) * common_part * (nvk[itemIdx][k] + alpha_v) / (nvkSum[itemIdx] + alphaSum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用于参数学习的不同推理方法主题模型的开发，例如变异推断和吉布斯采样<br>我们采用折叠的吉布斯抽样方法吉布斯抽样方法<br><em>代码体现</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Use Gibbs Sampling to update z[][]</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> m = <span class="number">0</span>; m &lt; M; m++) &#123;</span><br><span class="line">	<span class="keyword">int</span> N = docSet.docs.get(m).docWords.length;</span><br><span class="line">	<span class="keyword">int</span> userIdx = docSet.docs.get(m).userIdx;</span><br><span class="line">	<span class="keyword">int</span> itemIdx = docSet.docs.get(m).itemIdx;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; N; n++) &#123;</span><br><span class="line">		sampling(userIdx, itemIdx, m, n);  <span class="comment">// 这个函数实现了吉布斯采样</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200414000559240.png" alt="在这里插入图片描述"><br>来看看参数设计</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>[][] doc;<span class="comment">// sent index array</span></span><br><span class="line"><span class="keyword">int</span> V, K, M;<span class="comment">// vocabulary size, topic number, document number 词汇量，主题编号，文件编号</span></span><br><span class="line"><span class="keyword">int</span> userNum, itemNum; <span class="comment">// number of users, number of items,</span></span><br><span class="line"><span class="keyword">int</span>[][] z;<span class="comment">// doc-term topic</span></span><br><span class="line"><span class="keyword">int</span>[][] y; <span class="comment">// doc-term y index</span></span><br><span class="line"><span class="keyword">float</span> alpha_u, alpha_v; <span class="comment">// doc-topic dirichlet prior parameter doc-topic dirichlet先验参数</span></span><br><span class="line"><span class="keyword">float</span> beta; <span class="comment">// topic-word dirichlet prior parameter 主题词dirichlet先验参数</span></span><br><span class="line"><span class="keyword">float</span>[] eta;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[][] nkt;<span class="comment">// given topic k, count times of term t. K*V 给定主题k，计算项t的次数。 K * V</span></span><br><span class="line"><span class="keyword">int</span>[] nktSum;<span class="comment">// Sum for each row in nkt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[] Ny0; <span class="comment">// number of times sentence drawn from user 从用户抽取句子的次数</span></span><br><span class="line"><span class="keyword">int</span>[] Ny1; <span class="comment">// number of times sentence drawn from item 从物品抽取句子的次数</span></span><br><span class="line"><span class="keyword">double</span>[] NySum;</span><br><span class="line"><span class="keyword">double</span>[] bernpi;</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span>[][] phi;<span class="comment">// Parameters for topic-word distribution K*V 主题词分布的参数K * V</span></span><br><span class="line"><span class="keyword">double</span>[][] thetaU;<span class="comment">// Parameters for user-topic distribution 用户主题分布的参数</span></span><br><span class="line"><span class="keyword">double</span>[][] oldThetaU; <span class="comment">// user topic distribution</span></span><br><span class="line"><span class="keyword">double</span>[][] thetaV; <span class="comment">// parameters for item-topic distribution; 物品主题分布的参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[][] nuk; <span class="comment">// number of times topic for user u</span></span><br><span class="line"><span class="keyword">int</span>[][] nvk; <span class="comment">// number of times topic for item v</span></span><br><span class="line"><span class="keyword">int</span>[] nukSum; <span class="comment">// userNumber</span></span><br><span class="line"><span class="keyword">int</span>[] nvkSum; <span class="comment">// itemNum</span></span><br></pre></td></tr></table></figure>

<h3 id="2-Feature-Fusion"><a href="#2-Feature-Fusion" class="headerlink" title="2. Feature Fusion"></a>2. Feature Fusion</h3><p>融合嵌入<strong>词向量特征</strong>和<strong>基于评论的特征</strong>。<br>融合的方式常用的有三种：级联、相加、元素相乘。本文使用<strong>相加</strong>融合。<br><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user_embed = user_id_embed + user_text <span class="comment"># 相加</span></span><br><span class="line">item_embed = item_id_embed + item_text <span class="comment"># 相加</span></span><br><span class="line">user_embed = self.user_fusion(user_embed)</span><br><span class="line">item_embed = self.item_fusion(item_embed)</span><br></pre></td></tr></table></figure>

<p>在融合后直接加了 一个<strong>全连接层</strong>，这一层采用了<strong>ReLU激活函数</strong>。实验证明，全连接层提高了性能效果。<br><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">self.user_fusion = nn.Sequential(</span><br><span class="line">	nn.Linear(self.embed_size, self.embed_size),</span><br><span class="line">	nn.ReLU())</span><br><span class="line">self.item_fusion = nn.Sequential(</span><br><span class="line">	nn.Linear(self.embed_size, self.embed_size),</span><br><span class="line">	nn.ReLU())</span><br></pre></td></tr></table></figure>

<h3 id="3-Attentive-Interaction（最核心）"><a href="#3-Attentive-Interaction（最核心）" class="headerlink" title="3. Attentive Interaction（最核心）"></a>3. Attentive Interaction（最核心）</h3><h4 id="我们为了得到F："><a href="#我们为了得到F：" class="headerlink" title="我们为了得到F："></a>我们为了得到F：</h4><p><img src="https://img-blog.csdnimg.cn/20190524142236246.png" alt="在这里插入图片描述"><br>符号解释：</p>
<ul>
<li>pu代表用户向量，qi代表物品向量</li>
<li><strong>au,i是用户u对项目i的关注向量</strong></li>
<li>圈圈代表了逐个元素乘积 <blockquote>
<p>又称哈达玛积(Hadamard product)是矩阵的一类运算，若A=(aij)和B=(bij)是两个同阶矩阵，若cij=aij×bij,则称矩阵C=(cij)为A和B的哈达玛积<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ia2ltZy5jZG4uYmNlYm9zLmNvbS9waWMvYjdmZDUyNjZkMDE2MDkyNGE4ZGY1OTI4ZDkwNzM1ZmFlNmNkMzQwZQ?x-oss-process=image/format,png" alt="在这里插入图片描述"></p>
</blockquote>
</li>
</ul>
<p><em>代码体现</em></p>
<h2 id="interact-att-weights-user-embed-item-embed"><a href="#interact-att-weights-user-embed-item-embed" class="headerlink" title="interact = att_weights * user_embed * item_embed"></a><code>interact = att_weights * user_embed * item_embed</code></h2><h4 id="怎么得到a"><a href="#怎么得到a" class="headerlink" title="怎么得到a"></a>怎么得到a</h4><p><img src="https://img-blog.csdnimg.cn/20190524143412884.png" alt="在这里插入图片描述"><br>符号解释：<br> θ u ： 用户u的特征方面的概率分布<br>ϕ i ： 项目i的特征方面的概率分布<br> vT： 将隐藏层投影到输出注意力的权重向量。<br>作者将<strong>原有的主题向量</strong>和<strong>融合向量</strong>联合生成<strong>attention权重</strong>，在实验中证明该操作比单纯用融合向量的性能要好。<br><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">feature_all = torch.cat((</span><br><span class="line">			user_embed, item_embed), dim=<span class="number">-1</span>)</span><br><span class="line">att_weights = self.att_layer2(self.att_layer1(feature_all))</span><br><span class="line">att_weights = F.softmax(att_weights, dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.att_layer1 = nn.Sequential(</span><br><span class="line">	nn.Linear(<span class="number">2</span> * self.embed_size, <span class="number">1</span>),</span><br><span class="line">	nn.ReLU())</span><br><span class="line">self.att_layer2 = nn.Linear(<span class="number">1</span>, self.embed_size, bias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20190524143448998.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200414083825799.png" alt="在这里插入图片描述"></p>
<h3 id="4-Rating-Prediction"><a href="#4-Rating-Prediction" class="headerlink" title="4. Rating Prediction"></a>4. Rating Prediction</h3><p><strong>F被送到全连接层</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = self.rating_predict(interact)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20190524143834934.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.rating_predict = nn.Sequential(</span><br><span class="line">	nn.Linear(self.embed_size, self.embed_size),</span><br><span class="line">	nn.ReLU(),</span><br><span class="line">	nn.Dropout(p=self.dropout),</span><br><span class="line">	nn.Linear(self.embed_size, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>通过回归层获得预测的评分<br><img src="https://img-blog.csdnimg.cn/20190524144027144.png" alt="在这里插入图片描述"></p>
<h2 id="4-损失函数-amp-优化器"><a href="#4-损失函数-amp-优化器" class="headerlink" title="4. 损失函数&amp;优化器"></a>4. 损失函数&amp;优化器</h2><h3 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h3><p><img src="https://img-blog.csdnimg.cn/20190411230123100.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.MSELoss()</span><br></pre></td></tr></table></figure>

<h3 id="optimization："><a href="#optimization：" class="headerlink" title="optimization："></a>optimization：</h3><p>SGD随机梯度下降</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.Adam(</span><br><span class="line">	model.parameters(), </span><br><span class="line">	lr=FLAGS.lr, weight_decay=FLAGS.decay)</span><br></pre></td></tr></table></figure>

<p>三种代码的默认都是Adam,不知道为啥。</p>
<h2 id="5-数据集是怎么划分的"><a href="#5-数据集是怎么划分的" class="headerlink" title="5. 数据集是怎么划分的?"></a>5. 数据集是怎么划分的?</h2><p>数据集中采用Amazon评论数据集和yelp评论数据集：<br><img src="https://img-blog.csdnimg.cn/2019041123014974.png?" alt="在这里插入图片描述"><br>类别：婴儿、杂货店和美食家、家里和厨房、庭院草坪和花园、运动和户外 </p>
<p>项目中数据集的结构<br><img src="https://img-blog.csdnimg.cn/20200407195544758.png" alt="在这里插入图片描述"><br>dat 三列，前两个分别代表第u个用户，第i个的物品，第列是评分。构成用户评分矩阵<br>包括了train和test。<br><img src="https://img-blog.csdnimg.cn/20200413232059701.png" alt="在这里插入图片描述"><br>theta 六列，有序，五列。似乎是对top个词   top5<img src="https://img-blog.csdnimg.cn/20200413232257435.png" alt="在这里插入图片描述"></p>
<h2 id="6-实验的结果："><a href="#6-实验的结果：" class="headerlink" title="6. 实验的结果："></a>6. 实验的结果：</h2><p>Baseline的对比：<br>（1） BMF: 经典<strong>基于评分</strong>的<strong>矩阵分解</strong>模型；<br>（2） HFT：联合<strong>MF</strong>和<strong>LDA评分</strong>预测模型；<br>（3） RMR：采用<strong>混合高斯模型</strong>预测评分；<br>（4） RBLT：MF与LDA <strong>线性组合</strong>预测模型；<br>（5） TransNet：采用基于<strong>CNN</strong>建模方法。<br>实验的结果：<br>总体RMSE的对比：<br><img src="https://img-blog.csdnimg.cn/20190411230227298.png?" alt="在这里插入图片描述"><br>没有讨论的部分！(缺点 &amp; 改进的地方)</p>
<hr>
<h2 id="疑问："><a href="#疑问：" class="headerlink" title="疑问："></a>疑问：</h2><h5 id="1-这里面打开为什么什么都没有呀？"><a href="#1-这里面打开为什么什么都没有呀？" class="headerlink" title="1. 这里面打开为什么什么都没有呀？"></a>1. 这里面打开为什么什么都没有呀？</h5><p><img src="https://img-blog.csdnimg.cn/20200413223448958.png" alt="在这里插入图片描述"></p>
<h5 id="2-具体的怎么运用到现在的模型当中"><a href="#2-具体的怎么运用到现在的模型当中" class="headerlink" title="2. 具体的怎么运用到现在的模型当中"></a>2. 具体的怎么运用到现在的模型当中</h5><hr>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://blog.csdn.net/qq_35709076/article/details/90516371" target="_blank" rel="noopener">https://blog.csdn.net/qq_35709076/article/details/90516371</a><br><a href="https://blog.csdn.net/qq_30843221/article/details/89222266" target="_blank" rel="noopener">https://blog.csdn.net/qq_30843221/article/details/89222266</a><br><a href="https://blog.csdn.net/yjk13703623757/article/details/77016867" target="_blank" rel="noopener">https://blog.csdn.net/yjk13703623757/article/details/77016867</a><br><a href="https://blog.csdn.net/LoseInVain/article/details/88363776" target="_blank" rel="noopener">https://blog.csdn.net/LoseInVain/article/details/88363776</a></p>
</div></div><a class="button-hover more" href="2020/04/14/srf之论文阅读A3NCF/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/04/08/没能成功去泰迪杯的原因/">没能成功去泰迪杯的原因</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-08</time></div><div class="post-content"><div class="main-content content">已被加密啦</div></div><a class="button-hover more" href="2020/04/08/没能成功去泰迪杯的原因/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/04/05/生涯规划课之如何写一份优秀的简历/">生涯规划课之如何写一份优秀的简历</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-05</time></div><div class="post-content"><div class="main-content content">已被加密啦</div></div><a class="button-hover more" href="2020/04/05/生涯规划课之如何写一份优秀的简历/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/04/05/解析二级域名后看是否生效/">解析二级域名后看是否生效</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-05</time></div><div class="post-content"><div class="main-content content"><h5 id="阿里云的二级域名解析："><a href="#阿里云的二级域名解析：" class="headerlink" title="阿里云的二级域名解析："></a>阿里云的二级域名解析：</h5><p><strong>解析线路：</strong>选择 默认 （默认为必选项，如未设置会导致部分用户无法访问 )。<br><strong>TTL：</strong>为缓存时间，数值越小，<strong>修改记录各地生效时间越快</strong>，默认为10分钟。</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ping</span> yc.sanzzi.cn</span><br></pre></td></tr></table></figure>

<p>如果生效是以下这样的</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">正在 <span class="built_in">Ping</span> yc.sanzzi.cn [<span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span>] 具有 <span class="number">32</span> 字节的数据:</span><br><span class="line">来自 <span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span> 的回复: 字节=<span class="number">32</span> 时间=<span class="number">43</span>ms TTL=<span class="number">49</span></span><br><span class="line">来自 <span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span> 的回复: 字节=<span class="number">32</span> 时间=<span class="number">43</span>ms TTL=<span class="number">49</span></span><br><span class="line">来自 <span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span> 的回复: 字节=<span class="number">32</span> 时间=<span class="number">308</span>ms TTL=<span class="number">49</span></span><br><span class="line">来自 <span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span> 的回复: 字节=<span class="number">32</span> 时间=<span class="number">170</span>ms TTL=<span class="number">49</span></span><br><span class="line"></span><br><span class="line"><span class="number">123</span>.<span class="number">57</span>.<span class="number">242</span>.<span class="number">220</span> 的 <span class="built_in">Ping</span> 统计信息:</span><br><span class="line">    数据包: 已发送 = <span class="number">4</span>，已接收 = <span class="number">4</span>，丢失 = <span class="number">0</span> (<span class="number">0</span>% 丢失)，</span><br><span class="line">往返行程的估计时间(以毫秒为单位):</span><br><span class="line">    最短 = <span class="number">43</span>ms，最长 = <span class="number">308</span>ms，平均 = <span class="number">141</span>ms</span><br></pre></td></tr></table></figure>

<p>失败是</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Ping</span> 请求找不到主机 sanzi.sanzzi.cn。请检查该名称，然后重试。</span><br></pre></td></tr></table></figure>

</div></div><a class="button-hover more" href="2020/04/05/解析二级域名后看是否生效/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/04/01/srf之论文阅读Dr.VAE/">srf之论文阅读Dr.VAE</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-06</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="categories/DeepLearning/">DeepLearning</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="tags/srf/">srf</a></div></div><div class="post-content"><div class="main-content content"><h1 id="Dr-VAE-improving-drug-response-prediction-via-modeling-of-drug-perturbation-effects"><a href="#Dr-VAE-improving-drug-response-prediction-via-modeling-of-drug-perturbation-effects" class="headerlink" title="Dr.VAE: improving drug response prediction via modeling of drug perturbation effects"></a>Dr.VAE: improving drug response prediction via modeling of drug perturbation effects</h1><hr>
<h2 id="1-为什么要讲这个"><a href="#1-为什么要讲这个" class="headerlink" title="1. 为什么要讲这个?"></a>1. 为什么要讲这个?</h2><p><strong>Motivation:</strong><br>将<strong>生物系统的现有知识</strong>融入到这些方法中是<strong>提高预测性能</strong>的一个很有前途的途径。<br><strong>药物诱导转录组扰动效应的高通量细胞系分析</strong>(High-throughput cell line assays of drug-induced transcriptomic perturbation effects)是一项尚未完全纳入药物反应预测模型的先验知识。</p>
<h2 id="2-提出了什么方法"><a href="#2-提出了什么方法" class="headerlink" title="2. 提出了什么方法 ?"></a>2. 提出了什么方法 ?</h2><ul>
<li>药物反应变异自动编码器（<strong>Dr.VAE</strong>）（Drug Response Variational Autoencoder），这是一种<strong>深度生成模型</strong>，可以根据<strong>转录组扰动特征预测药物反应</strong>。Dr.VAE是一个概率图形模型，其中每个条件分布都由一个<strong>深度神经网络</strong>来计算。该模型共同学习药物反应预测因子和基因表达的低维潜在表示中的药物扰动效应生成模型。</li>
<li>结果：对于26种经过美国食品药品监督管理局（FDA）批准的测试药物，<strong>Dr.VAE的性能达到或优于标准分类方法</strong>。<blockquote>
<p>药物诱导转录组扰动效应，为什么谷歌不到相关信息！！？？</p>
</blockquote>
</li>
</ul>
<h2 id="3-传统方法有什么问题-（对比）"><a href="#3-传统方法有什么问题-（对比）" class="headerlink" title="3. 传统方法有什么问题?（对比）"></a>3. 传统方法有什么问题?（对比）</h2><p>在论文Introduction部分，并没有直接说之前的方法存在什么问题，而是罗列已有的成果。(略)<br>补充说一下Dr.VAE这个方法的具体启发：<br>Niepel 等人（2017）从最初的CMap开始研究了六种乳腺癌细胞系的转录组扰动，并结合表型药物反应测量来确定具有相似表型药物反应的细胞系在药物诱导的基因表达扰动中是否也具有相同的模式。<br>他们的分析得出结论，<strong>某些药物（细胞周期激酶抑制剂）就是这种情况，但对于其他药物，分子反应是细胞类型特异性的，对于某些药物-细胞系组合，显着的转录扰动对细胞没有影响</strong>。这些结果促使我们开发出一种统一的方法，该方法可以确定更复杂的分子扰动和表型反应关联，这些关联对于细胞系亚群可能是唯一的。</p>
<p>有关使用VAE的进展</p>
<ul>
<li>Way and Greene（2018）已证明VAE可以提取出癌症转录组谱的生物学意义。</li>
<li>Dincer 等（2018）在名为DeepProfile的药物反应预测方法中结合了<strong>预训练的VAE</strong>和<strong>单独训练的线性模型</strong>。</li>
</ul>
<h2 id="4-原理"><a href="#4-原理" class="headerlink" title="4. 原理"></a>4. 原理</h2><h3 id="简单了解一下VAE"><a href="#简单了解一下VAE" class="headerlink" title="简单了解一下VAE"></a>简单了解一下VAE</h3><h4 id="模型图："><a href="#模型图：" class="headerlink" title="模型图："></a>模型图：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDYvMTU4NjE3NTMyN18zODU5NzIucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"><br>下面这幅图可能容易理解一些<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9rZXh1ZS5mbS91c3IvdXBsb2Fkcy8yMDE4LzAzLzQxNjg4NzY2NjIucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h4 id="效果（目的）："><a href="#效果（目的）：" class="headerlink" title="效果（目的）："></a>效果（目的）：</h4><p><img src="https://img-blog.csdnimg.cn/20190226215534296.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2019022621561853.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="到这里，开始介绍Dr-VAE"><a href="#到这里，开始介绍Dr-VAE" class="headerlink" title="到这里，开始介绍Dr.VAE"></a>到这里，开始介绍Dr.VAE</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDQvMTU4NTk5MzY3OF82MzY0NzEucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><ul>
<li>x1是没有经过药物作用的，也就是没有转录组扰动效应</li>
<li>x2是经过药物作用后的。</li>
<li>z1,z2是隐参数，对于x1,x2</li>
<li>y是显示预测相关性的</li>
<li>z3 class-independent，独立的，正态分布<h4 id="公式："><a href="#公式：" class="headerlink" title="公式："></a>公式：</h4><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDYvMTU4NjE2NjI5NV85OTcxNTIucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></li>
</ul>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDQvMTU4NTk5MzY4N181MzM3Ny5wbmc?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<p>图a：Dr.VARE<br>图b:<br>图c:我们需要能够从观察到的形式对<strong>隐藏变量</strong>（z1,z2）进行有效推断变量，我们转向随机变分推断并引入真实<strong>后验的近似值q</strong>。<br>图d:Dr.VARE一点的例子<br>图f： PertVAE：无监督模型，用来研究药物效应模型对学习的潜在基因表达表示的贡献</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDYvMTU4NjE3MTM2NV83MjY5NTYucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"><br>不是很明白为什么这样子会好一些？？？</p>
<hr>
<h3 id="encoder-amp-decoder层次的设计"><a href="#encoder-amp-decoder层次的设计" class="headerlink" title="encoder&amp;decoder层次的设计"></a>encoder&amp;decoder层次的设计</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDYvMTU4NjE3NTI0MV8yOTQ2MTEucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="整个参数设计的代码体现"><a href="#整个参数设计的代码体现" class="headerlink" title="整个参数设计的代码体现"></a>整个参数设计的<em>代码体现</em></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = DrVAE(dim_x=dim_x, dim_s=dim_s, dim_y=dim_y, dim_z1=args.dim_z1, dim_z3=args.dim_z3,</span><br><span class="line">              dim_h_en_z1=args.enc_z1, dim_h_en_z3=args.enc_z3, dim_h_en_z2Fz1=args.enc_z2Fz1,</span><br><span class="line">              dim_h_de_z1=args.dec_z1, dim_h_de_x=args.dec_x, type_rec=<span class="string">'diag_gaussian'</span>,</span><br><span class="line">              dim_h_clf=args.class_y, type_y=args.type_y, prior_y=prior_y,</span><br><span class="line">              optim_alg=<span class="string">'adam'</span>, batch_size=args.batch_size, epochs=<span class="number">300</span>,</span><br><span class="line">              nonlinearity=<span class="string">'elu'</span>, L=args.L,</span><br><span class="line">              weight_decay=<span class="number">0.05</span>, dropout_rate=<span class="number">0.</span>, input_x_dropout=args.x_dropout, add_noise_var=args.noise_var,</span><br><span class="line">              learning_rate=<span class="number">0.0005</span>, yloss_rate=args.yloss_rate, clf_z1z2=<span class="literal">True</span>, clf_1sig=args.clf_1sig,</span><br><span class="line">              anneal_yloss_offset=args.anneal_yloss_offset,</span><br><span class="line">              kl_qz2pz2_rate=<span class="number">1.</span>, pertloss_rate=<span class="number">0.05</span>, anneal_perturb_rate_itermax=<span class="number">1</span>, anneal_perturb_rate_offset=<span class="number">0</span>,</span><br><span class="line">              use_s=args.useS, use_MMD=args.useMMD, kernel_MMD=<span class="string">'rbf_fourier'</span>, mmd_rate=args.mmd_rate,  <span class="comment">## &lt;= settings for "fairness" (like VFAE)</span></span><br><span class="line">              random_seed=args.rseed, log_txt=<span class="literal">None</span>  <span class="comment">#'DrVAE_SD_&#123;&#125;_&#123;&#125;.txt'.format(args.modelid, selected_drug)</span></span><br><span class="line">              )</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算KL散度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_fprop</span><span class="params">(self, z1, qz1, y)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有loss</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_compute_losses</span><span class="params">(self, x1, x2, s, y, L)</span>:</span></span><br><span class="line">   <span class="string">"""     </span></span><br><span class="line"><span class="string">   计算模型的所有损失。 对于未标记的数据，将y边缘化。</span></span><br><span class="line"><span class="string">   Compute all losses of the model. For unlabeled data marginalize y.</span></span><br><span class="line"><span class="string">   RECL - reconstruction loss E_&#123;q(z1|x1)&#125;[ p(x1|z1) ] </span></span><br><span class="line"><span class="string">   KLD  - kl-divergences of all the other matching q and p distributions所有其他匹配q和p分布的kl-散度</span></span><br><span class="line"><span class="string">   PERT - perturbation prediction loss E_&#123;p(z2|z1)q(z1|x1)&#125;[ p(x2|z2) ]</span></span><br><span class="line"><span class="string">   YL   - prediction loss on y (for labeled data)</span></span><br><span class="line"><span class="string">   MMD  - maximum mean discrepancy of z1 embedding w.r.t. grouping s</span></span><br><span class="line"><span class="string">   """</span></span><br></pre></td></tr></table></figure>

<h2 id="5-数据集是怎么划分的"><a href="#5-数据集是怎么划分的" class="headerlink" title="5. 数据集是怎么划分的?"></a>5. 数据集是怎么划分的?</h2><blockquote>
<p><strong>Training data sets</strong>：<strong>CTRPv2</strong>( Cancer Therapeutic Response Portal)  &amp;  <strong>CMap</strong> (CMap-L1000v1)<br><strong>Input data types</strong>：<strong>mRNA</strong> EXP (before &amp; after treatment)</p>
</blockquote>
<h3 id="两个数据集的基本介绍："><a href="#两个数据集的基本介绍：" class="headerlink" title="两个数据集的基本介绍："></a>两个数据集的基本介绍：</h3><p><strong>CTRPv2</strong>：为860个细胞系和481个药物化合物的组合<strong>提供了不同药物浓度下细胞系的相对生存能力</strong>。细胞系对<strong>药物治疗的敏感性</strong>通过<strong>剂量-反应曲线AAC</strong>上方的面积来量化，我们进一步采用瀑布法对连续的AAC进行二值化（Barretina等人，2012；Haibe-Kains等人，2013），<strong>将灵敏度预测任务转化为离散的分类任务。</strong>  <del>体现在哪里？</del><br><strong>CMap</strong>：筛选了19 811种药物化合物对多达77个细胞系中<strong>L1000个标志性基因表达</strong>的干扰效应。<br>在CMap中的实验并<strong>不能测量药物治疗的敏感性</strong>，但是一些细胞系也在CTRPv2中进行了独立的测试。我们<strong>交叉</strong>引用这些细胞系(取交集)，并将相应的标签分配给它们的扰动测量。</p>
<h3 id="实验数据选择标准："><a href="#实验数据选择标准：" class="headerlink" title="实验数据选择标准："></a>实验数据选择标准：</h3><ol>
<li>从CMap数据集，选择了在<strong>最常见浓度水平下对每种药物进行6小时的微扰实验</strong>。(如果细胞系没有在选定的浓度下进行检测，我们使用最接近的检测浓度。接下来，我们将对照组（DMSO载体）实验与药物扰动实验通过批次ID和微珠ID进行匹配，以最小化病例和对照组之间的批次效应。<del>？</del> 此外，我们通过相关性（&gt;0.75 Pearson q）过滤所选的病例对照对，以过滤出可能标记错误的实验或异常值。)</li>
<li>CTRPv2和CMap-L1000v1数据集共有<strong>973</strong>个<strong>共同基因</strong>。将<strong>每个基因的表达值标准化为零均值和单位方差</strong>。为了进一步的均匀化，包括去除批效应和两个合并数据之间的差异，我们还从集合数据集中去除了第一个主成分（解释了12.8%的变化）。</li>
</ol>
<p>基于以上两个标准，我们选择了<strong>26</strong>种在CTRPv2和CMap-L1000v1数据集中测试的<strong>药物</strong>：</p>
<ul>
<li>对于每种选择的药物，至少有<strong>8个不同的细胞系在CMap干扰实验中测试。</strong></li>
<li>CTRPv2中至少有20%的筛选细胞系在剂量-反应AAC二值化后<strong>对药物敏感</strong>。</li>
</ul>
<p>（忽略后面的可以看一下第一列的药物）<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDYvMTU4NjE1ODgwNV85NzAxNjAucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"><br><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## drug selection  </span></span><br><span class="line">drug_list_26 = [<span class="string">'omacetaxine mepesuccinate'</span>, <span class="string">'bortezomib'</span>, <span class="string">'vorinostat'</span>, <span class="string">'paclitaxel'</span>, <span class="string">'docetaxel'</span>, <span class="string">'topotecan'</span>,</span><br><span class="line">                <span class="string">'niclosamide'</span>, <span class="string">'valdecoxib'</span>,<span class="string">'teniposide'</span>, <span class="string">'vincristine'</span>, <span class="string">'prochlorperazine'</span>, <span class="string">'mitomycin'</span>, <span class="string">'lovastatin'</span>,</span><br><span class="line">                <span class="string">'gemcitabine'</span>, <span class="string">'dasatinib'</span>, <span class="string">'fluvastatin'</span>, <span class="string">'clofarabine'</span>, <span class="string">'sirolimus'</span>, <span class="string">'etoposide'</span>, <span class="string">'sitagliptin'</span>,</span><br><span class="line">                <span class="string">'decitabine'</span>, <span class="string">'PLX-4032'</span>, <span class="string">'fulvestrant'</span>, <span class="string">'bosutinib'</span>, <span class="string">'trifluoperazine'</span>, <span class="string">'ciclosporin'</span>]</span><br></pre></td></tr></table></figure>

<h2 id="7-交叉验证怎么做"><a href="#7-交叉验证怎么做" class="headerlink" title="7. 交叉验证怎么做?"></a>7. 交叉验证怎么做?</h2><p>通过执行20次重复的<strong>5折交叉验证</strong>，我们生成了100个训练验证测试数据。<br><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSplitsByGroupKFold</span><span class="params">(groups, fold, n_splits, shuffle, random_state)</span>:</span></span><br><span class="line">    <span class="string">'''the same group will not appear in two different folds'''</span></span><br></pre></td></tr></table></figure>

<h2 id="8-Discussion："><a href="#8-Discussion：" class="headerlink" title="8. Discussion："></a>8. Discussion：</h2><p>典型的判别前馈神经网络在药物反应预测中效果不佳，很可能是由于数据限制（特征数量与样本数量）所致。 我们表明，<strong>药物反应和扰动效应的联合生成模型</strong>在很大程度上缓解了这种情况，<strong>可能起到了有效的正则化和鲁棒的特征提取的作用</strong>，而不会产生过拟合的情况。</p>
<h3 id="局限性："><a href="#局限性：" class="headerlink" title="局限性："></a>局限性：</h3><ol>
<li>只考虑基因表达方式，<strong>没有额外整合</strong>甲基化、拷贝数变化、相互作用状态的<strong>多组预测因子。</strong></li>
<li>我们在每种药物最常见的浓度水平下，对治疗6小时后的CMap-L1000v1扰动进行建模。有人认为，<strong>6小时太短，许多反馈调节机制无法体现自己，因此这些实验本身并不能提供完整的转录反应图片</strong>。值得注意的是，药物细胞系活力测定通常在较长的治疗时间（如72小时）内完成。因此，我们也用24小时的微扰实验来训练我们的VAE博士，然而，<strong>由于这样的实验数量有限</strong>，这并没有提高我们的预测性能。</li>
<li>Dr.VAE所组成的每一个条件分布都是由一个神经网络参数化的。调整超参数以匹配数据复杂性的能力使Dr.VAE成为一个非常灵活的模型。<strong>由于我们选择了简单性，我们的神经网络大多有一个隐藏层，而分类后验函数和扰动函数是线性的。</strong> 然而，到目前为止，我们试图通过更复杂的分布使用更深的网络或使用规范化流来近似后验的尝试，<strong>并没有显著地提高性能来证明增加的复杂性。</strong></li>
</ol>
<hr>
<h2 id="补充知识："><a href="#补充知识：" class="headerlink" title="补充知识："></a>补充知识：</h2><h3 id="ablation-study消融实验"><a href="#ablation-study消融实验" class="headerlink" title="ablation study消融实验:"></a>ablation study消融实验:</h3><p>论证是什么起了作用，类似于中学学的控制变量。模型简化测试。看看取消掉一些模块后性能有没有影响。<br>本实验通过 Dr.VAE w / I来验证<br><em>代码体现</em></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_w_pert_identity</span><span class="params">(self, x1, x2, s=[])</span>:</span></span><br></pre></td></tr></table></figure>

<h3 id="Result部分"><a href="#Result部分" class="headerlink" title="Result部分"></a>Result部分</h3><p><em>代码体现</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classif_baseline_perf</span><span class="params">(xtrain, ytrain, xtest, ytest, svmkernel=<span class="string">'rbf'</span>, rseed=None)</span>:</span></span><br><span class="line">    <span class="string">'''这个包括了和 Random Forest、LogisticRegression、SVM、SVM w/ linear kernel的对比'''</span></span><br><span class="line">    data = [xtrain, ytrain, xtest, ytest]</span><br><span class="line">    perf = OrderedDict()</span><br><span class="line"></span><br><span class="line">    <span class="comment">## Random Forest</span></span><br><span class="line">    cl = sklearn.ensemble.RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=rseed)</span><br><span class="line">    rf_perf = measure_cl_perf(cl, <span class="string">'RF100'</span>, *data)</span><br><span class="line">    perf = concat_dicts(perf, rf_perf)</span><br><span class="line"></span><br><span class="line">	<span class="comment">## LogisticRegression</span></span><br><span class="line">    cl = sklearn.linear_model.LogisticRegressionCV(penalty=<span class="string">'l2'</span>, random_state=rseed)</span><br><span class="line">    lr_perf = measure_cl_perf(cl, <span class="string">'Ridge'</span>, *data)</span><br><span class="line">    perf = concat_dicts(perf, lr_perf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## SVM </span></span><br><span class="line">    cl = sklearn.svm.SVC(kernel=svmkernel, probability=<span class="literal">True</span>, random_state=rseed)</span><br><span class="line">    svm_perf = measure_cl_perf(cl, <span class="string">'SVM'</span> + svmkernel[:<span class="number">3</span>], *data)</span><br><span class="line">    perf = concat_dicts(perf, svm_perf)</span><br><span class="line">    <span class="comment"># SVM w/ linear kernel</span></span><br><span class="line">    cl = sklearn.svm.SVC(kernel=<span class="string">'linear'</span>, probability=<span class="literal">True</span>, random_state=rseed)</span><br><span class="line">    svm_perf = measure_cl_perf(cl, <span class="string">'SVMlin'</span>, *data)</span><br><span class="line">    perf = concat_dicts(perf, svm_perf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> perf</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmJzLmNzZG4ubmV0L3VwbG9hZC8yMDIwMDQvMDQvMTU4NTk5MzY5NF84MDQwMzYucG5n?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="ELU激活函数"><a href="#ELU激活函数" class="headerlink" title="ELU激活函数"></a>ELU激活函数</h3><p><img src="https://img-blog.csdn.net/20161120172142224#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdn.net/20160917160040231#pic_center" alt="在这里插入图片描述"><br>特点：</p>
<ul>
<li>融合了sigmoid和ReLU，左侧具有软饱和性，右侧无饱和性。</li>
<li>右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。</li>
<li>ELU的输出均值接近于零，所以收敛速度更快。</li>
</ul>
<h3 id="MMD"><a href="#MMD" class="headerlink" title="MMD"></a>MMD</h3><p>MMD（最大均值差异）是迁移学习，尤其是Domain adaptation （域适应）中使用最广泛（目前）的一种损失函数，主要用来度量两个不同但相关的分布的距离。</p>
<h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>是一种量化两种概率分布P和Q之间差异的方式，又叫相对熵。K-L散度能帮助我们度量使用一个分布来近似另一个分布时所损失的信息量。</p>
<h3 id="细胞系"><a href="#细胞系" class="headerlink" title="细胞系"></a>细胞系</h3><p>细胞系（cell line）指原代细胞培养物经首次传代成功后所繁殖的细胞群体。 也指可长期连续传代的培养细胞。</p>
<h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><h4 id="文章："><a href="#文章：" class="headerlink" title="文章："></a>文章：</h4><p>(VAE)<a href="https://blog.csdn.net/weixin_40955254/article/details/82315224" target="_blank" rel="noopener">https://blog.csdn.net/weixin_40955254/article/details/82315224</a><br>(VAE)<a href="https://blog.csdn.net/cjh_jinduoxia/article/details/84995156" target="_blank" rel="noopener">https://blog.csdn.net/cjh_jinduoxia/article/details/84995156</a><br>(KL散度)<a href="https://www.jianshu.com/p/43318a3dc715?isappinstalled=0" target="_blank" rel="noopener">https://www.jianshu.com/p/43318a3dc715?isappinstalled=0</a></p>
<h4 id="视频："><a href="#视频：" class="headerlink" title="视频："></a>视频：</h4><p>（白板推导VAE）<a href="https://www.bilibili.com/video/BV15E411w7Pz" target="_blank" rel="noopener">https://www.bilibili.com/video/BV15E411w7Pz</a></p>
</div></div><a class="button-hover more" href="2020/04/01/srf之论文阅读Dr.VAE/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/03/29/srf之论文汇报流程/">srf之论文汇报流程</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-03</time><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="categories/DeepLearning/">DeepLearning</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="tags/srf/">srf</a></div></div><div class="post-content"><div class="main-content content"><h2 id="论文将要讲述的方面"><a href="#论文将要讲述的方面" class="headerlink" title="论文将要讲述的方面"></a>论文将要讲述的方面</h2><ol>
<li>为什么要讲这个?（背景）</li>
<li>提出了什么 <strong>方法</strong> ?</li>
<li>传统方法有什么问题?（<strong>对比</strong>）</li>
<li><strong>原理</strong>简单讲一讲（数学方面要求不是很高，有代码实现更方便）?</li>
<li><strong>数据集</strong>是怎么<strong>划分</strong>的?</li>
<li><strong>交叉验证</strong>怎么做?</li>
</ol>
<h2 id="研究方法和主题"><a href="#研究方法和主题" class="headerlink" title="研究方法和主题"></a>研究方法和主题</h2><p>学长说在GCN方面不会有更深入的探寻了，会在以下几个方面找突破口</p>
<ul>
<li>Attention机制</li>
<li>知识图谱</li>
<li>异构图网络的学习</li>
<li>嵌入式学习</li>
</ul>
<h2 id="论文的选取"><a href="#论文的选取" class="headerlink" title="论文的选取"></a>论文的选取</h2><blockquote>
<p><strong>新</strong>（前沿），在期刊上发表的更好<br>有代码最好，有名字的模型在github上可以搜索的到</p>
</blockquote>
<h2 id="学长目前的想法"><a href="#学长目前的想法" class="headerlink" title="学长目前的想法"></a>学长目前的想法</h2><ul>
<li>SMILES收集之后：通过label encoding提取smiles的embedding<br><img src="srf%E4%B9%8B%E8%AE%BA%E6%96%87%E6%B1%87%E6%8A%A5%E6%B5%81%E7%A8%8B/%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt></li>
</ul>
</div></div><a class="button-hover more" href="2020/03/29/srf之论文汇报流程/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/02/26/web小项目/">Web小项目(react调试和部署)</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-03-29</time></div><div class="post-content"><div class="main-content content"><h2 id="如何在本地调试react项目"><a href="#如何在本地调试react项目" class="headerlink" title="如何在本地调试react项目"></a>如何在本地调试react项目</h2><blockquote>
<p>在项目终端下(pycharm)运行 <figure class="highlight plain"><figcaption><span>install```**安装依赖**</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">项目会生成**node_modules**目录</span><br><span class="line"></span><br><span class="line">我们在在项目终端下(pycharm)运行</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>npm start</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">浏览器会自动打开http://localhost:3000运行调试</span><br><span class="line"></span><br><span class="line">## 如何将本地的react项目部署到云服务器上</span><br><span class="line">我们在在项目终端下(pycharm)运行</span><br></pre></td></tr></table></figure>

<p>npm run build</p>
<pre><code>项目会生成了一个**build**目录

打开宝塔服务器页面，到相关网站下，将build页面下==static上传，以及和static平行的文件上传。==

至此，大功告成！
tips:感觉网上的教程大多数很复杂，暂时也不太明白他们做的原理(TODO)</code></pre></div></div><a class="button-hover more" href="2020/02/26/web小项目/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/02/25/爬虫之selenium报错——Chromedriver/">爬虫之selenium报错——Chromedriver</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-02</time></div><div class="post-content"><div class="main-content content"><p><strong>报错信息：</strong></p>
<figure class="highlight plain"><figcaption><span>executable needs to be in PATH.```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">**解决方法：**</span><br><span class="line">### 关于Chromedriver如何配置环境变量问题解决[^1]</span><br><span class="line">到环境变量中加上‪C:\Program Files (x86)\Google\Chrome\Application</span><br><span class="line"></span><br><span class="line">### windows下更新环境变量不需要重启系统快速生效的方法[^2]</span><br></pre></td></tr></table></figure>

<p>set path=test<br>echo %path%<br>```</p>
<h3 id="如果还没有生效的话-3"><a href="#如果还没有生效的话-3" class="headerlink" title="如果还没有生效的话[^3]"></a>如果还没有生效的话[^3]</h3><p><strong>原来还要放到Python目录下</strong><br>很多人都反应上面两步做了也没有生效</p>
<p>最后……<br>自己入自己的坑，才是最绝望的。chromedriver和chrome 多少是眼残的事……</p>
<p>参考：<br>[^1]: <a href="https://blog.csdn.net/qq_41429288/article/details/80472064" target="_blank" rel="noopener">https://blog.csdn.net/qq_41429288/article/details/80472064</a><br>[^2]: <a href="https://blog.csdn.net/u010770041/article/details/49915089" target="_blank" rel="noopener">https://blog.csdn.net/u010770041/article/details/49915089</a><br>[^3]: <a href="https://blog.csdn.net/weixin_37185329/article/details/80493281" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37185329/article/details/80493281</a></p>
</div></div><a class="button-hover more" href="2020/02/25/爬虫之selenium报错——Chromedriver/#more">阅读全文</a></div><div class="recent-post-item"><a class="post-title" href="2020/02/23/ideaVim-easymotion 插件/">ideaVim-easymotion 插件</a><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 更新于 2020-04-02</time></div><div class="post-content"><div class="main-content content"><h4 id="作用：辅助（优化）ideaVim的"><a href="#作用：辅助（优化）ideaVim的" class="headerlink" title="作用：辅助（优化）ideaVim的"></a>作用：辅助（优化）ideaVim的</h4><p>主要是通过提升了<strong>跳转</strong>方式<br>一般的：<br><code>gg, G</code>最上、最下<br><code>Ctrl-D/U</code>下几步，上几步</p>
<p>网上教程不多，具体更多详细教程：<br><a href="http://www.wklken.me/posts/2015/06/07/vim-plugin-easymotion.html" target="_blank" rel="noopener">http://www.wklken.me/posts/2015/06/07/vim-plugin-easymotion.html</a></p>
</div></div><a class="button-hover more" href="2020/02/23/ideaVim-easymotion 插件/#more">阅读全文</a></div></div><div id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="page/5/">5</a><a class="extend next" rel="next" href="page/2/"><i class="fas fa-angle-right"></i></a></div></div></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fas fa-user"></i></span><span id="busuanzi_value_site_uv"></span><span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fas fa-eye"></i></span><span id="busuanzi_value_site_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Rr-shan</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/haruto.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>